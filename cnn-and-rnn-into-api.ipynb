{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b32407",
   "metadata": {},
   "source": [
    "# Stuttering Detection Using CNN and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3728d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2209eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape of the audio data\n",
    "input_shape = (431, 128, 1) # because n_mels = 128\n",
    "#input_shape = (128, 431, 1) #original\n",
    "max_time_steps = 431 #originally 300\n",
    "num_features = 128\n",
    "train_time_series_data = 38400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf54a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio files and extract features\n",
    "audio_dir = \"C:\\\\Users\\\\DeLL\\\\Downloads\\\\AllAudio\"\n",
    "audio_files = os.listdir(audio_dir)\n",
    "audio_features = []\n",
    "for file in audio_files:\n",
    "    audio_path = os.path.join(audio_dir, file)\n",
    "    audio_data, sr = librosa.load(audio_path, sr=22050, mono=True, duration=10)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sr, n_mels=num_features)\n",
    "    log_spectrogram = librosa.power_to_db(spectrogram)\n",
    "    log_spectrogram = np.expand_dims(log_spectrogram, axis=-1)\n",
    "    audio_features.append(log_spectrogram)\n",
    "audio_features = np.array(audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7dfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract features from audio files\n",
    "def extract_features(audio_path):\n",
    "    audio_dir = \"C:\\\\Users\\\\DeLL\\\\Downloads\\\\AllAudio\"\n",
    "    y, sr = librosa.load(audio_dir)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=22050, n_mfcc=40, n_fft=1024, hop_length=512)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    features = np.concatenate([mfcc, mfcc_delta, mfcc_delta2])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d61517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stuttering labels\n",
    "labels = pd.read_csv(\"fyplabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7214e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. ],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [2.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [2. ],\n",
       "       [1. ],\n",
       "       [2. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [2. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db6b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(audio_features, labels, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a333037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the data to match the RNN input shape\n",
    "train_data = np.transpose(train_data, (0, 2, 1, 3))\n",
    "test_data = np.transpose(test_data, (0, 2, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c01e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f7a50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN architecture\n",
    "rnn_input = Input(shape=(max_time_steps, num_features))\n",
    "rnn_model = LSTM(units=64, return_sequences=False)(rnn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23a996fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the CNN and RNN models\n",
    "combined_model = tf.keras.layers.concatenate([cnn_model.output, rnn_model])\n",
    "output_layer = Dense(1, activation='sigmoid')(combined_model)\n",
    "model = Model(inputs=[cnn_model.input, rnn_input], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd73401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2704b120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3/3 [==============================] - 7s 1s/step - loss: -24.6662 - accuracy: 0.4627 - val_loss: -95.6169 - val_accuracy: 0.9310\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 3s 851ms/step - loss: -215.5852 - accuracy: 0.8657 - val_loss: -273.1368 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2734f9c10f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([train_data, np.random.rand(train_data.shape[0], max_time_steps, num_features)], train_labels, epochs=2, batch_size=32, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d779a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 123ms/step\n",
      "The audio clip 1 contains stuttering.\n",
      "The audio clip 2 contains stuttering.\n",
      "The audio clip 3 contains stuttering.\n",
      "The audio clip 4 contains stuttering.\n",
      "The audio clip 5 contains stuttering.\n",
      "The audio clip 6 contains stuttering.\n",
      "The audio clip 7 contains stuttering.\n",
      "The audio clip 8 contains stuttering.\n",
      "The audio clip 9 contains stuttering.\n",
      "The audio clip 10 contains stuttering.\n",
      "The audio clip 11 contains stuttering.\n",
      "The audio clip 12 contains stuttering.\n",
      "The audio clip 13 contains stuttering.\n",
      "The audio clip 14 contains stuttering.\n",
      "The audio clip 15 contains stuttering.\n",
      "The audio clip 16 contains stuttering.\n",
      "The audio clip 17 contains stuttering.\n",
      "The audio clip 18 contains stuttering.\n",
      "The audio clip 19 contains stuttering.\n",
      "The audio clip 20 contains stuttering.\n",
      "The audio clip 21 contains stuttering.\n",
      "The audio clip 22 contains stuttering.\n",
      "The audio clip 23 contains stuttering.\n",
      "The audio clip 24 contains stuttering.\n",
      "The audio clip 25 contains stuttering.\n",
      "The audio clip 26 contains stuttering.\n",
      "The audio clip 27 contains stuttering.\n",
      "The audio clip 28 contains stuttering.\n",
      "The audio clip 29 contains stuttering.\n",
      "The audio clip 30 contains stuttering.\n",
      "The audio clip 31 contains stuttering.\n",
      "The audio clip 32 contains stuttering.\n",
      "The audio clip 33 contains stuttering.\n",
      "The audio clip 34 contains stuttering.\n",
      "The audio clip 35 contains stuttering.\n",
      "The audio clip 36 contains stuttering.\n",
      "The audio clip 37 contains stuttering.\n",
      "The audio clip 38 contains stuttering.\n",
      "The audio clip 39 contains stuttering.\n",
      "The audio clip 40 contains stuttering.\n",
      "The audio clip 41 contains stuttering.\n",
      "The audio clip 42 contains stuttering.\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([test_data, np.random.rand(test_data.shape[0], max_time_steps, num_features)])\n",
    "\n",
    "# Print prediction\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i][0] > 0.5:\n",
    "        print(\"The audio clip {} contains stuttering.\".format(i+1))\n",
    "    else:\n",
    "        print(\"The audio clip {} is fluent.\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c570d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Interruptions'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e29ac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio clip 1 has full stuttering.\n",
      "Audio clip 2 has medium stuttering.\n",
      "Audio clip 3 has full stuttering.\n",
      "Audio clip 4 has medium stuttering.\n",
      "Audio clip 5 has full stuttering.\n",
      "Audio clip 6 has full stuttering.\n",
      "Audio clip 7 has full stuttering.\n",
      "Audio clip 8 has full stuttering.\n",
      "Audio clip 9 has full stuttering.\n",
      "Audio clip 10 has full stuttering.\n",
      "Audio clip 11 has full stuttering.\n",
      "Audio clip 12 has full stuttering.\n",
      "Audio clip 13 has full stuttering.\n",
      "Audio clip 14 has full stuttering.\n",
      "Audio clip 15 has full stuttering.\n",
      "Audio clip 16 has full stuttering.\n",
      "Audio clip 17 has full stuttering.\n",
      "Audio clip 18 has full stuttering.\n",
      "Audio clip 19 has full stuttering.\n",
      "Audio clip 20 has full stuttering.\n",
      "Audio clip 21 has full stuttering.\n",
      "Audio clip 22 has full stuttering.\n",
      "Audio clip 23 has full stuttering.\n",
      "Audio clip 24 has full stuttering.\n",
      "Audio clip 25 has full stuttering.\n",
      "Audio clip 26 has full stuttering.\n",
      "Audio clip 27 has full stuttering.\n",
      "Audio clip 28 has full stuttering.\n",
      "Audio clip 29 has full stuttering.\n",
      "Audio clip 30 has full stuttering.\n",
      "Audio clip 31 has full stuttering.\n",
      "Audio clip 32 has full stuttering.\n",
      "Audio clip 33 has full stuttering.\n",
      "Audio clip 34 has full stuttering.\n",
      "Audio clip 35 has full stuttering.\n",
      "Audio clip 36 has full stuttering.\n",
      "Audio clip 37 has full stuttering.\n",
      "Audio clip 38 has full stuttering.\n",
      "Audio clip 39 has full stuttering.\n",
      "Audio clip 40 has full stuttering.\n",
      "Audio clip 41 has full stuttering.\n",
      "Audio clip 42 has full stuttering.\n",
      "Audio clip 43 has full stuttering.\n",
      "Audio clip 44 has full stuttering.\n",
      "Audio clip 45 has full stuttering.\n",
      "Audio clip 46 has full stuttering.\n",
      "Audio clip 47 has medium stuttering.\n",
      "Audio clip 48 has full stuttering.\n",
      "Audio clip 49 has full stuttering.\n",
      "Audio clip 50 has full stuttering.\n",
      "Audio clip 51 has full stuttering.\n",
      "Audio clip 52 has full stuttering.\n",
      "Audio clip 53 has full stuttering.\n",
      "Audio clip 54 has full stuttering.\n",
      "Audio clip 55 has full stuttering.\n",
      "Audio clip 56 has medium stuttering.\n",
      "Audio clip 57 has medium stuttering.\n",
      "Audio clip 58 has full stuttering.\n",
      "Audio clip 59 has full stuttering.\n",
      "Audio clip 60 has non-stuttering.\n",
      "Audio clip 61 has full stuttering.\n",
      "Audio clip 62 has full stuttering.\n",
      "Audio clip 63 has full stuttering.\n",
      "Audio clip 64 has full stuttering.\n",
      "Audio clip 65 has full stuttering.\n",
      "Audio clip 66 has full stuttering.\n",
      "Audio clip 67 has full stuttering.\n",
      "Audio clip 68 has full stuttering.\n",
      "Audio clip 69 has full stuttering.\n",
      "Audio clip 70 has full stuttering.\n",
      "Audio clip 71 has full stuttering.\n",
      "Audio clip 72 has full stuttering.\n",
      "Audio clip 73 has full stuttering.\n",
      "Audio clip 74 has full stuttering.\n",
      "Audio clip 75 has full stuttering.\n",
      "Audio clip 76 has full stuttering.\n",
      "Audio clip 77 has full stuttering.\n",
      "Audio clip 78 has full stuttering.\n",
      "Audio clip 79 has full stuttering.\n",
      "Audio clip 80 has full stuttering.\n",
      "Audio clip 81 has full stuttering.\n",
      "Audio clip 82 has full stuttering.\n",
      "Audio clip 83 has medium stuttering.\n",
      "Audio clip 84 has full stuttering.\n",
      "Audio clip 85 has full stuttering.\n",
      "Audio clip 86 has full stuttering.\n",
      "Audio clip 87 has full stuttering.\n",
      "Audio clip 88 has full stuttering.\n",
      "Audio clip 89 has full stuttering.\n",
      "Audio clip 90 has full stuttering.\n",
      "Audio clip 91 has full stuttering.\n",
      "Audio clip 92 has full stuttering.\n",
      "Audio clip 93 has full stuttering.\n",
      "Audio clip 94 has full stuttering.\n",
      "Audio clip 95 has full stuttering.\n",
      "Audio clip 96 has full stuttering.\n",
      "Audio clip 97 has full stuttering.\n",
      "Audio clip 98 has full stuttering.\n",
      "Audio clip 99 has full stuttering.\n",
      "Audio clip 100 has full stuttering.\n",
      "Audio clip 101 has medium stuttering.\n",
      "Audio clip 102 has full stuttering.\n",
      "Audio clip 103 has full stuttering.\n",
      "Audio clip 104 has full stuttering.\n",
      "Audio clip 105 has full stuttering.\n",
      "Audio clip 106 has full stuttering.\n",
      "Audio clip 107 has full stuttering.\n",
      "Audio clip 108 has full stuttering.\n",
      "Audio clip 109 has full stuttering.\n",
      "Audio clip 110 has full stuttering.\n",
      "Audio clip 111 has full stuttering.\n",
      "Audio clip 112 has full stuttering.\n",
      "Audio clip 113 has full stuttering.\n",
      "Audio clip 114 has full stuttering.\n",
      "Audio clip 115 has full stuttering.\n",
      "Audio clip 116 has full stuttering.\n",
      "Audio clip 117 has full stuttering.\n",
      "Audio clip 118 has full stuttering.\n",
      "Audio clip 119 has full stuttering.\n",
      "Audio clip 120 has full stuttering.\n",
      "Audio clip 121 has full stuttering.\n",
      "Audio clip 122 has full stuttering.\n",
      "Audio clip 123 has full stuttering.\n",
      "Audio clip 124 has low stuttering.\n",
      "Audio clip 125 has full stuttering.\n",
      "Audio clip 126 has low stuttering.\n",
      "Audio clip 127 has full stuttering.\n",
      "Audio clip 128 has full stuttering.\n",
      "Audio clip 129 has low stuttering.\n",
      "Audio clip 130 has full stuttering.\n",
      "Audio clip 131 has full stuttering.\n",
      "Audio clip 132 has medium stuttering.\n",
      "Audio clip 133 has full stuttering.\n",
      "Audio clip 134 has full stuttering.\n",
      "Audio clip 135 has medium stuttering.\n",
      "Audio clip 136 has full stuttering.\n",
      "Audio clip 137 has full stuttering.\n",
      "Audio clip 138 has full stuttering.\n"
     ]
    }
   ],
   "source": [
    "# Load the stuttering labels\n",
    "labels = pd.read_csv(\"fyplabels.csv\")\n",
    "\n",
    "# Define a function to map label values to categories\n",
    "def categorize_label(label_value):\n",
    "    if label_value == 1:\n",
    "        return \"full stuttering\"\n",
    "    elif label_value == 1.5:\n",
    "        return \"medium stuttering\"\n",
    "    elif label_value == 2:\n",
    "        return \"low stuttering\"\n",
    "    else:\n",
    "        return \"non-stuttering\"\n",
    "\n",
    "# Categorize the labels\n",
    "test_label_categories = [categorize_label(label) for label in labels['Interruptions'].values]\n",
    "\n",
    "for i, category in enumerate(test_label_categories):\n",
    "    print(\"Audio clip {} has {}.\".format(i+1, category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b2488",
   "metadata": {},
   "source": [
    "# API Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b523da51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
